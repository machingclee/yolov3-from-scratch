{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Construction of YOLO v3 Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\r\n",
    "import torch.nn as nn"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "_x = torch.randn(1, 3, 416, 416)\r\n",
    "_x = nn.Conv2d(3, 3, 3, 1, padding=1)(_x)\r\n",
    "_x = nn.Conv2d(3, 3, 3, 2, padding=1)(_x)\r\n",
    "_x = nn.Conv2d(3, 3, 3, 2, padding=1)(_x)\r\n",
    "_x = nn.Conv2d(3, 3, 3, 2, padding=1)(_x)\r\n",
    "print(_x.shape)\r\n",
    "_x = nn.Conv2d(3, 3, 3, 2, padding=1)(_x)\r\n",
    "print(_x.shape)\r\n",
    "_x = nn.Conv2d(3, 3, 3, 2, padding=1)(_x)\r\n",
    "print(_x.shape)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 3, 52, 52])\n",
      "torch.Size([1, 3, 26, 26])\n",
      "torch.Size([1, 3, 13, 13])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "\"\"\" \r\n",
    "Information about architecture config:\r\n",
    "Tuple is structured by (filters, kernel_size, stride) \r\n",
    "Every conv is a same convolution. \r\n",
    "List is structured by \"B\" indicating a residual block followed by the number of repeats\r\n",
    "\"S\" is for scale prediction block and computing the yolo loss\r\n",
    "\"U\" is for upsampling the feature map and concatenating with a previous layer\r\n",
    "\"\"\"\r\n",
    "#416x416\r\n",
    "darknet_config = [\r\n",
    "    (32, 3, 1),     #416x416, i.e., padding=\"same\" convolution\r\n",
    "    (64, 3, 2),     #208x208, i.e., resize by half convolution\r\n",
    "    [\"B\", 1],       #208x208\r\n",
    "    (128, 3, 2),    #104x104\r\n",
    "    [\"B\", 2],       #104x104\r\n",
    "    (256, 3, 2),    #52x52\r\n",
    "    [\"B\", 8],       #52x52\r\n",
    "    (512, 3, 2),    #26x26\r\n",
    "    [\"B\", 8],       #26x26\r\n",
    "    (1024, 3, 2),   #None, 1024, 13, 13\r\n",
    "    [\"B\", 4],       # To this point is Darknet-53  #13x13\r\n",
    "    (512, 1, 1),    #None, 512, 13, 13\r\n",
    "    (1024, 3, 1),   #None, 1024, 13, 13\r\n",
    "    \"S\",\r\n",
    "    (256, 1, 1),\r\n",
    "    \"U\",            #None, 256+512 = 3*256, x, x\r\n",
    "    (256, 1, 1),\r\n",
    "    (512, 3, 1),\r\n",
    "    \"S\",\r\n",
    "    (128, 1, 1),\r\n",
    "    \"U\",            #None, 128+256 = 3*128\r\n",
    "    (128, 1, 1),\r\n",
    "    (256, 3, 1),\r\n",
    "    \"S\",\r\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "class CNNBlock(nn.Module):\r\n",
    "    def __init__(self, in_channels, out_channels, bn_act=True, **kwargs):\r\n",
    "        super(CNNBlock, self).__init__()\r\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, bias=not bn_act, **kwargs)\r\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\r\n",
    "        self.leaky = nn.LeakyReLU(0.1)\r\n",
    "        self.use_bn_act = bn_act\r\n",
    "    \r\n",
    "    def forward(self, x):\r\n",
    "        x = self.conv(x)\r\n",
    "\r\n",
    "        if not self.use_bn_act:\r\n",
    "            return x\r\n",
    "        else:\r\n",
    "            x = self.bn(x)\r\n",
    "            x = self.leaky(x)\r\n",
    "            return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "class ResidualBlock(nn.Module):\r\n",
    "    def __init__(self, channels, use_skip_connection=True, num_repeats=1):\r\n",
    "        super(ResidualBlock, self).__init__()\r\n",
    "        self.layers = nn.ModuleList()\r\n",
    "        for _ in range(num_repeats):\r\n",
    "            # spatial dimension is preserved\r\n",
    "            self.layers += [\r\n",
    "                nn.Sequential(\r\n",
    "                    CNNBlock(channels, channels//2, kernel_size = 1),\r\n",
    "                    CNNBlock(channels//2, channels, kernel_size = 3, padding = 1)\r\n",
    "                )\r\n",
    "            ]\r\n",
    "        \r\n",
    "        self.use_skip_connection = use_skip_connection\r\n",
    "        self.num_repeats =  num_repeats\r\n",
    "    \r\n",
    "    def forward(self, x):\r\n",
    "        for layer in self.layers:\r\n",
    "            if self.use_skip_connection:\r\n",
    "                x = layer(x) + x\r\n",
    "            else: \r\n",
    "                x = layer(x)\r\n",
    "\r\n",
    "        return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Scales mean 13x13, 26x26, 52x52\r\n",
    "class ScalePrediction(nn.Module):\r\n",
    "    def __init__(self, in_channels, num_classes):\r\n",
    "        super(ScalePrediction, self).__init__()\r\n",
    "        # pred preserve spatial dimension\r\n",
    "        self.pred = nn.Sequential(\r\n",
    "            CNNBlock(in_channels, 2 * in_channels, kernel_size=3, padding=1),\r\n",
    "            CNNBlock(2 * in_channels, 3 * (num_classes + 5), bn_act=False, kernel_size=1)\r\n",
    "        )\r\n",
    "        self.num_classes = num_classes\r\n",
    "    \r\n",
    "    def forward(self, x):\r\n",
    "        \"\"\"\r\n",
    "        Finally reshape and permute into: \r\n",
    "            [\r\n",
    "                batch_size, \r\n",
    "                anchor_nums,\r\n",
    "                num_of_vertical_cells, \r\n",
    "                num_of_horizontal_cells\r\n",
    "                class_scores + bounding_box_predictions, \r\n",
    "            ]\r\n",
    "        \"\"\"\r\n",
    "        return (\r\n",
    "            self\r\n",
    "            .pred(x)\r\n",
    "            .reshape(x.shape[0], 3, self.num_classes + 5, x.shape[2], x.shape[3])\r\n",
    "            .permute(0, 1, 3, 4, 2)            \r\n",
    "        )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "class YOLOv3(nn.Module):\r\n",
    "    def __init__(self, in_channels=3, num_classes=20):\r\n",
    "        super(YOLOv3, self).__init__()\r\n",
    "        self.num_classes = num_classes\r\n",
    "        self.in_channels = in_channels\r\n",
    "        self.layers = self._create_conv_layers()\r\n",
    "    \r\n",
    "    def forward(self, x):\r\n",
    "        outputs = []\r\n",
    "        route_connections=[]\r\n",
    "\r\n",
    "        for layer in self.layers:\r\n",
    "            if isinstance(layer, ScalePrediction):\r\n",
    "                output = layer(x)\r\n",
    "                outputs.append(output)\r\n",
    "                # i.e., don't treat the ScalePrediction as a chain in our network,\r\n",
    "                # just record the result and continue\r\n",
    "                continue\r\n",
    "            \r\n",
    "            # this will be executed as long as layer is not ScalePrediction\r\n",
    "            x = layer(x)\r\n",
    "\r\n",
    "            if isinstance(layer, ResidualBlock) and layer.num_repeats==8:\r\n",
    "                route_connections.append(x)\r\n",
    "                \r\n",
    "            elif isinstance(layer, nn.Upsample):\r\n",
    "                x=torch.cat([x, route_connections[-1]], dim = 1)\r\n",
    "                route_connections.pop()\r\n",
    "             \r\n",
    "        return outputs\r\n",
    "\r\n",
    "    def _create_conv_layers(self):\r\n",
    "        layers = nn.ModuleList()\r\n",
    "        # initialize input channels\r\n",
    "        in_channels = self.in_channels\r\n",
    "        for module in darknet_config:\r\n",
    "            if isinstance(module, tuple):\r\n",
    "                # it is a tuple iff it is a CNNBlock\r\n",
    "                out_channels, kernel_size, stride = module\r\n",
    "                layers.append(\r\n",
    "                    CNNBlock(\r\n",
    "                        in_channels=in_channels,\r\n",
    "                        out_channels = out_channels,\r\n",
    "                        kernel_size = kernel_size,\r\n",
    "                        stride = stride,\r\n",
    "                        padding = 1 if kernel_size == 3 else 0\r\n",
    "                    )\r\n",
    "                )\r\n",
    "                in_channels = out_channels\r\n",
    "            \r\n",
    "            elif isinstance(module, list):\r\n",
    "                # it is a list iff it is a resudial block\r\n",
    "                num_repeats = module[1]\r\n",
    "                layers.append(\r\n",
    "                    ResidualBlock(\r\n",
    "                        in_channels, \r\n",
    "                        num_repeats=num_repeats\r\n",
    "                    )\r\n",
    "                )\r\n",
    "            \r\n",
    "            elif isinstance(module, str):\r\n",
    "                # Scale Prediction\r\n",
    "                if module == \"S\":\r\n",
    "                    layers += [\r\n",
    "                        ResidualBlock(\r\n",
    "                            in_channels,\r\n",
    "                            use_skip_connection=False,\r\n",
    "                            num_repeats=1\r\n",
    "                        ),\r\n",
    "                        CNNBlock(\r\n",
    "                            in_channels, \r\n",
    "                            in_channels//2,\r\n",
    "                            kernel_size=1\r\n",
    "                        ),\r\n",
    "                        ScalePrediction(\r\n",
    "                            in_channels//2, \r\n",
    "                            num_classes=self.num_classes\r\n",
    "                        )\r\n",
    "                    ]\r\n",
    "                    # Scale prediction will not be counted in the chain of conv nets, \r\n",
    "                    # it will be stored and \"continued\" in the for loop\r\n",
    "                    # so the \"current num of channels\" is the CNNBlock's one\r\n",
    "                    in_channels = in_channels//2\r\n",
    "                # Upsampling\r\n",
    "                elif module == \"U\":\r\n",
    "                    layers.append(nn.Upsample(scale_factor=2))\r\n",
    "                    # every time a [\"B\", 8] is executed, when then double the in_channel\r\n",
    "                    # the output of [\"B\", 8] then get concated to this upsampled output\r\n",
    "                    # this *3 is a summarized pattern of the network\r\n",
    "                    in_channels = in_channels*3\r\n",
    "        \r\n",
    "        return layers"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def test():\r\n",
    "    num_classes=20\r\n",
    "    IMAGE_SIZE=416\r\n",
    "    \r\n",
    "    model = YOLOv3(num_classes=num_classes)\r\n",
    "    x = torch.randn((2, 3, IMAGE_SIZE, IMAGE_SIZE))\r\n",
    "    assert model(x)[0].shape == (2, 3, IMAGE_SIZE//32, IMAGE_SIZE//32, num_classes + 5)\r\n",
    "    assert model(x)[1].shape == (2, 3, IMAGE_SIZE//16, IMAGE_SIZE//16, num_classes + 5)\r\n",
    "    assert model(x)[2].shape == (2, 3, IMAGE_SIZE//8, IMAGE_SIZE//8, num_classes + 5)\r\n",
    "    print(\"success\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "test()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "success\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "os.getcwd()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\jameslcc\\\\repo\\\\Python\\\\yolov3-from-scratch\\\\Yolov3'"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "sys.path.append(os.getcwd())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "import numpy as np\r\n",
    "import os\r\n",
    "import pandas as pd\r\n",
    "import torch\r\n",
    "import sys\r\n",
    "\r\n",
    "\r\n",
    "from PIL import Image, ImageFile\r\n",
    "from torch.utils.data import Dataset, DataLoader\r\n",
    "\r\n",
    "from utils.utils import (\r\n",
    "    iou_width_height as iou,\r\n",
    "    non_max_suppression as nms\r\n",
    ")\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "class YOLODataset(Dataset):\r\n",
    "    def __init__(\r\n",
    "        self, \r\n",
    "        csv_file, \r\n",
    "        img_dir, \r\n",
    "        label_dir, \r\n",
    "        anchors,\r\n",
    "        image_size=416,\r\n",
    "        strides=[13, 26, 52],\r\n",
    "        num_classes=20,\r\n",
    "        transform=None\r\n",
    "        ):\r\n",
    "        super(YOLODataset, self).__init__()\r\n",
    "        self.annotations = pd.read_csv(csv_file)\r\n",
    "        self.img_dir = img_dir\r\n",
    "        self.label_dir = label_dir\r\n",
    "        self.transform = transform\r\n",
    "        self.num_anchors = torch.tensor(anchors[0] + anchors[1] + anchors[2])\r\n",
    "        self.num_anchors_per_scale = self.num_anchors // 3\r\n",
    "        self.num_classes = num_classes\r\n",
    "        self.image_size = image_size\r\n",
    "        self.strides = strides\r\n",
    "        self.ignore_iou_threshold = 0.5\r\n",
    "    \r\n",
    "    def __len__(self):\r\n",
    "        return len(self.annotations)\r\n",
    "    \r\n",
    "    def __getitem__(self, index):\r\n",
    "        label_path = os.path.join(\r\n",
    "            self.label_dir, \r\n",
    "            self.annotations.iloc[index, 1]\r\n",
    "        )\r\n",
    "        # there will be several bboxes for a single label\r\n",
    "        bboxes = np.roll(np.loadtxt(fname=label_path, delimiter=\" \", ndim=2), 4, axis=1).tolist()\r\n",
    "        img_path = os.path(\r\n",
    "            self.img_dir, \r\n",
    "            self.annotations.iloc[index, 0]\r\n",
    "        )\r\n",
    "        image = np.array(Image.open(img_path).convert(\"RGB\"))\r\n",
    "\r\n",
    "        if self.transform:\r\n",
    "            augmentations = self.transform(image=image, bboxes=bboxes)\r\n",
    "            image = augmentations[\"image\"]\r\n",
    "            bboxes = augmentations[\"bboxes\"]\r\n",
    "        # (p_o, x, y, w, h, class)\r\n",
    "        targets = [torch.zeros((self.num_anchors//3, s, s, 6)) for s in self.strides]\r\n",
    "\r\n",
    "        for box in bboxes:\r\n",
    "            # box: (None, 1, 2)  self.anchors: (3,2)\r\n",
    "            # on multiplication: say (5, 1, 2) x (3, 2) --> (5,3,2) x (5,3,2)\r\n",
    "            # then iou will act on them\r\n",
    "            iou_anchors = iou(torch.tensor(box[2:4]), self.anchors)\r\n",
    "            anchor_indices = iou_anchors.argsort(desceding=True, dim=0)\r\n",
    "            x, y, width, height, class_label = box\r\n",
    "            has_anchor = [False, False, False]\r\n",
    "\r\n",
    "            for anchor_idx in anchor_indices:\r\n",
    "                scale_idx = anchor_idx // self.num_anchors_per_scale\r\n",
    "                anchor_on_scale = anchor_idx % self.num_anchors_per_scale\r\n",
    "                s = self.strides[scale_idx]\r\n",
    "                i, j = int(s*y), int(s*x)\r\n",
    "                anchor_taken = targets[scale_idx][anchor_on_scale, i, j, 0]\r\n",
    "\r\n",
    "                if not anchor_taken and not has_anchor[scale_idx]:\r\n",
    "                    targets[scale_idx][anchor_on_scale, i, j, 0] = 1\r\n",
    "                    x_cell, y_cell = s*x - j, s*y - i\r\n",
    "                    width_cell, height_cell = (width*s, height*s)\r\n",
    "                    box_coordinates = torch.tensor(\r\n",
    "                        [x_cell, y_cell, width_cell, height_cell]\r\n",
    "                    )\r\n",
    "                    targets[scale_idx][anchor_on_scale,i,j, 1:5] = box_coordinates\r\n",
    "                    targets[scale_idx][anchor_on_scale,i,j, 5] = int(class_label)\r\n",
    "                \r\n",
    "                elif not anchor_taken and iou_anchors[anchor_idx] > self.ignore_iou_threshold:\r\n",
    "                    targets[scale_idx][anchor_on_scale, i, j, 0] = -1 # ignore this prediction     \r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "import torch \r\n",
    "import torch.nn as nn\r\n",
    "\r\n",
    "from utils.utils import intersection_over_union\r\n",
    "\r\n",
    "class YoloLoss(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super().__init__()\r\n",
    "        self.mse = nn.MSELoss()\r\n",
    "        self.bce = nn.BCEWithLogitsLoss()\r\n",
    "        self.entropy = nn.CrossEntropyLoss()\r\n",
    "        self.sigmoid = nn.Sigmoid()\r\n",
    "\r\n",
    "        self.lambda_clas = 1\r\n",
    "        self.lambda_noobj = 10\r\n",
    "        self.lambda_obj = 1\r\n",
    "        self.lambda_box = 10\r\n",
    "\r\n",
    "    def forward(self, predictions, target, anchors):\r\n",
    "        obj = target[..., 0] == 1\r\n",
    "        noobj = target[..., 0] == 0\r\n",
    "\r\n",
    "        # no object loss\r\n",
    "        no_object_loss = self.bce(\r\n",
    "            (predictions[..., 0:1][noobj]),\r\n",
    "            (target[..., 0:1][noobj])\r\n",
    "        )\r\n",
    "\r\n",
    "        # object loss\r\n",
    "        anchors = anchors.reshape(1, 3, 1, 1, 2)\r\n",
    "        box_preds = torch.cat(\r\n",
    "            [self.sigmoid(predictions[...,1:3]),\r\n",
    "            torch.exp(predictions[..., 3:5]*anchors)],\r\n",
    "            dim=-1\r\n",
    "        )\r\n",
    "        ious = intersection_over_union(box_preds[obj], target[..., 1:5][obj]).detach()\r\n",
    "        object_loss = self.bce(\r\n",
    "            (predictions[...,0:1][obj]), (ious * target[..., 0:1][obj])\r\n",
    "        )\r\n",
    "\r\n",
    "        # box coordinate loss\r\n",
    "        predictions[..., 1:3]= self.sigmoid(\r\n",
    "            predictions[..., 1:3]\r\n",
    "        )\r\n",
    "        target[...,3:5]= torch.log(\r\n",
    "          1e-16 + target[..., 3:5] / anchors\r\n",
    "        )\r\n",
    "        box_loss = self.mse(\r\n",
    "            predictions[..., 1:5][obj], target[...,1:5][obj]\r\n",
    "        )\r\n",
    "        \r\n",
    "\r\n",
    "        # class loss\r\n",
    "        class_loss = self.entropy(\r\n",
    "            predictions[..., 5:][obj], target[..., 5][obj].long()\r\n",
    "        )\r\n",
    "\r\n",
    "        return (\r\n",
    "                self.lambda_box  *  box_loss \r\n",
    "            +   self.lambda_obj * object_loss\r\n",
    "            +   self.lambda_noobj * object_loss\r\n",
    "            +   self.lambda_class * class_loss\r\n",
    "        )\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "from utils import config\r\n",
    "\r\n",
    "def get_loaders(train_csv_path, test_csv_path):\r\n",
    "    IMAGE_SIZE = config.IMAGE_SIZE\r\n",
    "    train_dataset = YOLODataset(\r\n",
    "        train_csv_path,\r\n",
    "        transform=config.train_transforms,\r\n",
    "        strides=[IMAGE_SIZE // 32, IMAGE_SIZE // 16, IMAGE_SIZE // 8],\r\n",
    "        img_dir=config.IMG_DIR,\r\n",
    "        label_dir=config.LABEL_DIR,\r\n",
    "        anchors=config.ANCHORS,\r\n",
    "    )\r\n",
    "    test_dataset = YOLODataset(\r\n",
    "        test_csv_path,\r\n",
    "        transform=config.test_transforms,\r\n",
    "        strides=[IMAGE_SIZE // 32, IMAGE_SIZE // 16, IMAGE_SIZE // 8],\r\n",
    "        img_dir=config.IMG_DIR,\r\n",
    "        label_dir=config.LABEL_DIR,\r\n",
    "        anchors=config.ANCHORS,\r\n",
    "    )\r\n",
    "    train_loader = DataLoader(\r\n",
    "        dataset=train_dataset,\r\n",
    "        batch_size=config.BATCH_SIZE,\r\n",
    "        num_workers=config.NUM_WORKERS,\r\n",
    "        pin_memory=config.PIN_MEMORY,\r\n",
    "        shuffle=True,\r\n",
    "        drop_last=False,\r\n",
    "    )\r\n",
    "    test_loader = DataLoader(\r\n",
    "        dataset=test_dataset,\r\n",
    "        batch_size=config.BATCH_SIZE,\r\n",
    "        num_workers=config.NUM_WORKERS,\r\n",
    "        pin_memory=config.PIN_MEMORY,\r\n",
    "        shuffle=False,\r\n",
    "        drop_last=False,\r\n",
    "    )\r\n",
    "\r\n",
    "    train_eval_dataset = YOLODataset(\r\n",
    "        train_csv_path,\r\n",
    "        transform=config.test_transforms,\r\n",
    "        strides=[IMAGE_SIZE // 32, IMAGE_SIZE // 16, IMAGE_SIZE // 8],\r\n",
    "        img_dir=config.IMG_DIR,\r\n",
    "        label_dir=config.LABEL_DIR,\r\n",
    "        anchors=config.ANCHORS,\r\n",
    "    )\r\n",
    "    train_eval_loader = DataLoader(\r\n",
    "        dataset=train_eval_dataset,\r\n",
    "        batch_size=config.BATCH_SIZE,\r\n",
    "        num_workers=config.NUM_WORKERS,\r\n",
    "        pin_memory=config.PIN_MEMORY,\r\n",
    "        shuffle=False,\r\n",
    "        drop_last=False,\r\n",
    "    )\r\n",
    "\r\n",
    "    return train_loader, test_loader, train_eval_loader\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "import torch\r\n",
    "import torch.optim as optim\r\n",
    "\r\n",
    "from tqdm import tqdm\r\n",
    "from utils.utils import (\r\n",
    "    mean_average_precision,\r\n",
    "    cells_to_bboxes,\r\n",
    "    get_evaluation_bboxes,\r\n",
    "    save_checkpoint,\r\n",
    "    load_checkpoint,\r\n",
    "    check_class_accuracy,\r\n",
    "    plot_couple_examples\r\n",
    ")\r\n",
    "\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings(\"ignore\")\r\n",
    "\r\n",
    "torch.backends.cudnn.benchmark = True"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "def train_fn(train_loader, model, optimizer, loss_fn, scaler, scaled_anchors):\r\n",
    "    loop = tqdm(train_loader, leave=True)\r\n",
    "    losses = []\r\n",
    "    for batch_idx, (x, y) in enumerate(loop):\r\n",
    "        x = x.to(config.DEVICE)\r\n",
    "        y0, y1, y2 = (\r\n",
    "            y[0].to(config.DEVICE),\r\n",
    "            y[1].to(config.DEVICE),\r\n",
    "            y[2].to(config.DEVICE),\r\n",
    "        )\r\n",
    "\r\n",
    "        with torch.cuda.amp.autocast():\r\n",
    "            out = model(x)\r\n",
    "            loss = (\r\n",
    "                loss_fn(out[0], y0, scaled_anchors[0])\r\n",
    "                + loss_fn(out[1], y1, scaled_anchors[1])\r\n",
    "                + loss_fn(out[2], y2, scaled_anchors[2])\r\n",
    "            )\r\n",
    "\r\n",
    "        losses.append(loss.item())\r\n",
    "        optimizer.zero_grad()\r\n",
    "        scaler.scale(loss).backward()\r\n",
    "        scaler.step(optimizer)\r\n",
    "        scaler.update()\r\n",
    "\r\n",
    "        # update progress bar\r\n",
    "        mean_loss = sum(losses) / len(losses)\r\n",
    "        loop.set_postfix(loss=mean_loss)\r\n",
    "\r\n",
    "def main():\r\n",
    "    model = YOLOv3(num_classes=config.NUM_CLASSES).to(config.DEVICE)\r\n",
    "    optimizer = optim.Adam(\r\n",
    "        model.parameters(), lr=config.LEARNING_RATE, weight_decay=config.WEIGHT_DECAY\r\n",
    "    )\r\n",
    "\r\n",
    "    loss_fn = YoloLoss()\r\n",
    "    scaler = torch.cuda.amp.GradScaler()\r\n",
    "\r\n",
    "    train_loader, test_loader, train_eval_loader = get_loaders(\r\n",
    "        train_csv_path= config.DATASET + \"/8examples.csv\",\r\n",
    "        test_csv_path = config.DATASET + \"/8examples.csv\"\r\n",
    "    )\r\n",
    "\r\n",
    "    if config.LOAD_MODEL:\r\n",
    "        load_checkpoint(\r\n",
    "            config.CHECKPOINT_FILE, model, optimizer, config.LEARNING_RATE\r\n",
    "        )\r\n",
    "    \r\n",
    "    scaled_anchors = (\r\n",
    "        torch.tensor(config.ANCHORS)\r\n",
    "        * torch.tensor(config.S).unsqueeze(1).unsqueeze(2).repeat(1,3,2)\r\n",
    "    ).to(config.DEVICE)\r\n",
    "\r\n",
    "\r\n",
    "    for epoch in range(config.NUM_EPOCHS):\r\n",
    "        train_fn(test_loader, model, optimizer,loss_fn, scaler, scaled_anchors)\r\n",
    "\r\n",
    "        if config.SAVE_MODEL:\r\n",
    "            save_checkpoint(model, optimizer)\r\n",
    "\r\n",
    "        #if config.SAVE_MODEL:\r\n",
    "        #    save_checkpoint(model, optimizer, filename=f\"checkpoint.pth.tar\")\r\n",
    "\r\n",
    "        #print(f\"Currently epoch {epoch}\")\r\n",
    "        #print(\"On Train Eval loader:\")\r\n",
    "        #print(\"On Train loader:\")\r\n",
    "        #check_class_accuracy(model, train_loader, threshold=config.CONF_THRESHOLD)\r\n",
    "\r\n",
    "        if epoch > 0 and epoch % 3 == 0:\r\n",
    "            check_class_accuracy(\r\n",
    "                model, \r\n",
    "                test_loader, \r\n",
    "                threshold=config.CONF_THRESHOLD\r\n",
    "            )\r\n",
    "            pred_boxes, true_boxes = get_evaluation_bboxes(\r\n",
    "                test_loader,\r\n",
    "                model,\r\n",
    "                iou_threshold=config.NMS_IOU_THRESH,\r\n",
    "                anchors=config.ANCHORS,\r\n",
    "                threshold=config.CONF_THRESHOLD,\r\n",
    "            )\r\n",
    "            mapval = mean_average_precision(\r\n",
    "                pred_boxes,\r\n",
    "                true_boxes,\r\n",
    "                iou_threshold=config.MAP_IOU_THRESH,\r\n",
    "                box_format=\"midpoint\",\r\n",
    "                num_classes=config.NUM_CLASSES,\r\n",
    "            )\r\n",
    "            print(f\"MAP: {mapval.item()}\")\r\n",
    "            model.train()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "main()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/1 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 15696, 22796, 25692, 21460) exited unexpectedly",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\Miniconda3\\envs\\dl\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    989\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 990\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    991\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dl\\lib\\multiprocessing\\queues.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    107\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m                         \u001b[1;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-25-0f32707ed5fd>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[0mtrain_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaled_anchors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSAVE_MODEL\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-0f32707ed5fd>\u001b[0m in \u001b[0;36mtrain_fn\u001b[1;34m(train_loader, model, optimizer, loss_fn, scaler, scaled_anchors)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mlosses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mloop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         y0,y1,y2 = (\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dl\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1184\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1185\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1186\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m                 \u001b[1;31m# Update and possibly print the progressbar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dl\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dl\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1186\u001b[1;33m             \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dl\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1150\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1152\u001b[1;33m                 \u001b[0msuccess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1153\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dl\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1001\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfailed_workers\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1002\u001b[0m                 \u001b[0mpids_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m', '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfailed_workers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1003\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'DataLoader worker (pid(s) {}) exited unexpectedly'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpids_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1004\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1005\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 15696, 22796, 25692, 21460) exited unexpectedly"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# panda experiment\r\n",
    "# mydict = [\r\n",
    "# {'a': 1, 'b': 2, 'c': 3, 'd': 4},\r\n",
    "# {'a': 100, 'b': 200, 'c': 300, 'd': 400},\r\n",
    "# {'a': 1000, 'b': 2000, 'c': 3000, 'd': 4000 }\r\n",
    "# ]\r\n",
    "# df = pd.DataFrame(mydict)\r\n",
    "# np.array(df.iloc[1,1:4])\r\n",
    "# result: array([200, 300, 400], dtype=int64)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# np.loadtxt experiment\r\n",
    "# ndmin is the least dimension\r\n",
    "# delimiter means a string that we split the line\r\n",
    "# np.roll(x, shift, axis)\r\n",
    "# shift the element of x to the right (-ve means left) cylically along the given axis \r\n",
    "\r\n",
    "# row = np.loadtxt(fname=\"./dataset/labels/000001.txt\", delimiter=\" \", ndmin=2)\r\n",
    "# print(row)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('dl': conda)"
  },
  "interpreter": {
   "hash": "6b1f039069d6172ef73d0b939796bfc9640c29d76fb9386aa8f90c7cbce2c865"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}